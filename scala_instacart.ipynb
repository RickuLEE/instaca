{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[doc](https://spark.apache.org/docs/latest/sql-getting-started.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Point: SparkSession\n",
    "The entry point into all functionality in Spark is the SparkSession class. To create a basic SparkSession, just use SparkSession.builder():<br>\n",
    "#### 取得SparkSession的物件，SparkSession功能為程式的起點，類比Java的main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@2401199\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@2401199"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession\n",
    "  .builder()\n",
    "  .appName(\"Spark SQL instacart example\")\n",
    "  .config(\"spark.some.config.option\", \"some-value\")\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4.4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DataFrames<br>\n",
    "#### 讀取資料instacart的資料集(看到後面面程式碼會發現，我只使用products.csv 和 order_products__train.csv來跑關聯性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aisles = [aisle_id: int, aisle: string]\n",
       "departments = [department_id: int, department: string]\n",
       "order_products_prior = [order_id: int, product_id: int ... 2 more fields]\n",
       "order_products_train = [order_id: int, product_id: int ... 2 more fields]\n",
       "orders = [order_id: int, user_id: int ... 5 more fields]\n",
       "products = [product_id: int, product_name: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[product_id: int, product_name: string ... 2 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val aisles = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(\"aisles.csv\")\n",
    "val departments = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(\"departments.csv\")\n",
    "val order_products_prior = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(\"order_products__prior.csv\")\n",
    "val order_products_train = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(\"order_products__train.csv\")\n",
    "val orders = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(\"orders.csv\")\n",
    "val products= spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(\"products.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running SQL Queries Programmatically\n",
    "The sql function on a SparkSession enables applications to run SQL queries programmatically and returns the result as a DataFrame.\n",
    "#### 建立tempview可以使用sql語法進行操作資料(ex: inner join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Register the DataFrame as a SQL temporary view\n",
    "aisles.createOrReplaceTempView(\"aisles\")\n",
    "departments.createOrReplaceTempView(\"departments\")\n",
    "order_products_prior.createOrReplaceTempView(\"order_products_prior\")\n",
    "order_products_train.createOrReplaceTempView(\"order_products_train\")\n",
    "orders.createOrReplaceTempView(\"orders\")\n",
    "products.createOrReplaceTempView(\"products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|order_id|               items|\n",
      "+--------+--------------------+\n",
      "|    1342|[Raw Shrimp, Seed...|\n",
      "|    1591|[Cracked Wheat, S...|\n",
      "|    4519|[Beet Apple Carro...|\n",
      "+--------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rawData = [product_name: string, order_id: int]\n",
       "baskets = [order_id: int, items: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, items: array<string>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Organize the data by shopping basket\n",
    "import org.apache.spark.sql.functions.{collect_set,col,count}\n",
    "//order_products_train只顯示product_id，為了知道product_id的代表什麼商品，與order.csv進行inner join\n",
    "val rawData = spark.sql(\"\"\"\n",
    "select p.product_name, o.order_id \n",
    "from products p \n",
    "inner join order_products_train o \n",
    "where o.product_id = p.product_id\"\"\")\n",
    "//order_products_train的欄位 : order_id, product_id,add_to_cart_order ，但我只想得知每次消費購物籃有哪幾項商品，以order_id groupby\n",
    "val baskets = rawData.groupBy(\"order_id\").agg(collect_set(\"product_name\").alias(\"items\"))\n",
    "baskets.createOrReplaceTempView(\"baskets\")\n",
    "baskets.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.Dataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets.getClass.getName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML Model\n",
    "[Frequent Pattern Mining - RDD-based API](https://spark.apache.org/docs/latest/mllib-frequent-pattern-mining.html#fp-growth)   文件<br>\n",
    "[購物籃分析的說明](https://towardsdatascience.com/a-gentle-introduction-on-market-basket-analysis-association-rules-fa4b986a40ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baskets_ds = [items: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[items: array<string>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Extract out the items \n",
    "//轉成模型可以吃的資料型態\n",
    "val baskets_ds = spark.sql(\"select items from baskets\").as[Array[String]].toDF(\"items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               items|\n",
      "+--------------------+\n",
      "|[Raw Shrimp, Seed...|\n",
      "|[Cracked Wheat, S...|\n",
      "|[Beet Apple Carro...|\n",
      "|             [Vodka]|\n",
      "|[Globe Eggplant, ...|\n",
      "|[Organic Baby Spi...|\n",
      "|[Reduced Fat Crac...|\n",
      "|[Organic Red Onio...|\n",
      "|[Organic Cripps P...|\n",
      "|[Organic Baby Spi...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "qwe = [items: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[items: array<string>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//看一下data的模樣，每一列代表每次購物的消費項目\n",
    "baskets_ds.createOrReplaceTempView(\"watch\")\n",
    "val qwe = spark.sql(\"select * from watch\")\n",
    "qwe.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fpgrowth = fpgrowth_af81f84fbda6\n",
       "model = fpgrowth_af81f84fbda6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fpgrowth_af81f84fbda6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.fpm.FPGrowth\n",
    "// Use FPGrowth\n",
    "//設定參數(support、confidence)李御璽老師教學時設定是50%，但實際在跑code時，設50%符合的筆數較少\n",
    "val fpgrowth = new FPGrowth().setItemsCol(\"items\").setMinSupport(0.001).setMinConfidence(0)\n",
    "val model = fpgrowth.fit(baskets_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequent Itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mostPopularItemInABasket = [items: array<string>, freq: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[items: array<string>, freq: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Display frequent itemsets\n",
    "val mostPopularItemInABasket = model.freqItemsets\n",
    "mostPopularItemInABasket.createOrReplaceTempView(\"mostPopularItemInABasket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|               items|freq|\n",
      "+--------------------+----+\n",
      "|[Organic Hass Avo...| 710|\n",
      "|[Organic Raspberr...| 649|\n",
      "|[Organic Baby Spi...| 587|\n",
      "|[Organic Raspberr...| 531|\n",
      "|[Organic Hass Avo...| 497|\n",
      "|[Organic Avocado,...| 484|\n",
      "|[Organic Avocado,...| 477|\n",
      "|[Limes, Large Lem...| 452|\n",
      "|[Organic Cucumber...| 424|\n",
      "|[Limes, Organic A...| 389|\n",
      "|[Organic Raspberr...| 381|\n",
      "|[Organic Avocado,...| 379|\n",
      "|[Organic Baby Spi...| 376|\n",
      "|[Organic Blueberr...| 374|\n",
      "|[Large Lemon, Org...| 371|\n",
      "|[Organic Cucumber...| 366|\n",
      "|[Organic Lemon, O...| 353|\n",
      "|[Limes, Organic A...| 352|\n",
      "|[Organic Whole Mi...| 339|\n",
      "|[Organic Avocado,...| 334|\n",
      "+--------------------+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sqlDF = [items: array<string>, freq: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[items: array<string>, freq: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//尋找消費者購物的模式，設定購物項目最少2樣商品，並者出頻率最高的消費組合\n",
    "val sqlDF = spark.sql(\"select items, freq from mostPopularItemInABasket where size(items) > 2 order by freq desc limit 20\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.Dataset"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlDF.getClass.getName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rules\n",
    "#### 簡單說明:消費者購買褲子，我有多少信心說他會買內褲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Generated Association Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ifThen = [antecedent: array<string>, consequent: array<string> ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[antecedent: array<string>, consequent: array<string> ... 2 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Display generated association rules.\n",
    "val ifThen = model.associationRules\n",
    "ifThen.createOrReplaceTempView(\"ifThen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n",
      "|     antecedent (if)|   consequent (then)|         confidence|\n",
      "+--------------------+--------------------+-------------------+\n",
      "|[Organic Raspberr...|[Bag of Organic B...| 0.5984251968503937|\n",
      "|[Organic Cucumber...|[Bag of Organic B...|           0.546875|\n",
      "|[Organic Kiwi, Or...|[Bag of Organic B...| 0.5459770114942529|\n",
      "|[Organic Navel Or...|[Bag of Organic B...| 0.5412186379928315|\n",
      "|[Yellow Onions, S...|            [Banana]| 0.5357142857142857|\n",
      "|[Organic Whole St...|[Bag of Organic B...| 0.5314685314685315|\n",
      "|[Organic Navel Or...|[Bag of Organic B...| 0.5283018867924528|\n",
      "|[Organic Raspberr...|[Bag of Organic B...|  0.521099116781158|\n",
      "|[Organic D'Anjou ...|[Bag of Organic B...| 0.5170454545454546|\n",
      "|[Organic Unsweete...|[Bag of Organic B...| 0.5141065830721003|\n",
      "|[Organic Broccoli...|[Bag of Organic B...| 0.5048231511254019|\n",
      "|[Organic Lemon, O...|[Bag of Organic B...| 0.4989106753812636|\n",
      "|[Organic Hass Avo...|[Bag of Organic B...|0.49393939393939396|\n",
      "|[Organic Fuji App...|            [Banana]| 0.4915254237288136|\n",
      "|[Honeycrisp Apple...|            [Banana]| 0.4868421052631579|\n",
      "|[Organic Large Ex...|[Bag of Organic B...| 0.4838709677419355|\n",
      "|[Organic Gala App...|[Bag of Organic B...| 0.4837905236907731|\n",
      "|[Organic Navel Or...|[Bag of Organic B...| 0.4821002386634845|\n",
      "|[Organic Kiwi, Or...|[Bag of Organic B...| 0.4792332268370607|\n",
      "|[Organic Carrot B...|[Bag of Organic B...|0.47315436241610737|\n",
      "+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sqlDF2 = [antecedent (if): array<string>, consequent (then): array<string> ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[antecedent (if): array<string>, consequent (then): array<string> ... 1 more field]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlDF2 = spark.sql(\"select antecedent as `antecedent (if)`, consequent as `consequent (then)`, confidence from ifThen order by confidence desc limit 20\")\n",
    "sqlDF2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
